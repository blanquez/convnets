# -*- coding: utf-8 -*-
"""VCP2-a3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fE6dbtgGBMQUys1ioAqaqfn7GlifvMlQ
"""

# -*- coding: utf-8 -*-

#########################################################################
################### OBTENER LA BASE DE DATOS ############################
#########################################################################

# Descargar las imágenes de http://www.vision.caltech.edu/visipedia/CUB-200.html
# Descomprimir el fichero.
# Descargar también el fichero list.tar.gz, descomprimirlo y guardar los ficheros
# test.txt y train.txt dentro de la carpeta de imágenes anterior. Estos 
# dos ficheros contienen la partición en train y test del conjunto de datos.

##### EN CASO DE USAR COLABORATORY
# Sube tanto las imágenes como los ficheros text.txt y train.txt a tu drive.
# Después, ejecuta esta celda y sigue las instrucciones para montar 
# tu drive en colaboratory.
from google.colab import drive
drive.mount('/content/drive')



#########################################################################
################ CARGAR LAS LIBRERÍAS NECESARIAS ########################
#########################################################################

# Terminar de rellenar este bloque con lo que vaya haciendo falta

# Importar librerías necesarias
import numpy as np
import keras
import keras.utils as np_utils
from keras.preprocessing.image import load_img,img_to_array
import matplotlib.pyplot as plt

# Importar el optimizador a usar
from keras.optimizers import Adam

# Importar el modelo ResNet50 y su respectiva función de preprocesamiento,
from keras.applications.resnet import ResNet50, preprocess_input

#########################################################################
################## FUNCIÓN PARA LEER LAS IMÁGENES #######################
#########################################################################

# Dado un fichero train.txt o test.txt y el path donde se encuentran los
# ficheros y las imágenes, esta función lee las imágenes
# especificadas en ese fichero y devuelve las imágenes en un vector y 
# sus clases en otro.

def leerImagenes(vec_imagenes, path):
  clases = np.array([img.split('/')[0] for img in vec_imagenes])
  imagenes = np.array([img_to_array(load_img(path + "/" + img, 
                                             target_size = (224, 224))) 
                       for img in vec_imagenes])
  return imagenes, clases

#########################################################################
############# FUNCIÓN PARA CARGAR EL CONJUNTO DE DATOS ##################
#########################################################################

# Usando la función anterior, y dado el path donde se encuentran las
# imágenes y los archivos "train.txt" y "test.txt", devuelve las 
# imágenes y las clases de train y test para usarlas con keras
# directamente.

def cargarDatos(path):
  # Cargamos los ficheros
  train_images = np.loadtxt(path + "/train.txt", dtype = str)
  test_images = np.loadtxt(path + "/test.txt", dtype = str)
  
  # Leemos las imágenes con la función anterior
  train, train_clases = leerImagenes(train_images, path)
  test, test_clases = leerImagenes(test_images, path)
  
  # Pasamos los vectores de las clases a matrices 
  # Para ello, primero pasamos las clases a números enteros
  clases_posibles = np.unique(np.copy(train_clases))
  for i in range(len(clases_posibles)):
    train_clases[train_clases == clases_posibles[i]] = i
    test_clases[test_clases == clases_posibles[i]] = i

  # Después, usamos la función to_categorical()
  train_clases = np_utils.to_categorical(train_clases, 200)
  test_clases = np_utils.to_categorical(test_clases, 200)
  
  # Barajar los datos
  train_perm = np.random.permutation(len(train))
  train = train[train_perm]
  train_clases = train_clases[train_perm]

  test_perm = np.random.permutation(len(test))
  test = test[test_perm]
  test_clases = test_clases[test_perm]
  
  return train, train_clases, test, test_clases

#########################################################################
######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########
#########################################################################

# Esta función devuelve el accuracy de un modelo, definido como el 
# porcentaje de etiquetas bien predichas frente al total de etiquetas.
# Como parámetros es necesario pasarle el vector de etiquetas verdaderas
# y el vector de etiquetas predichas, en el formato de keras (matrices
# donde cada etiqueta ocupa una fila, con un 1 en la posición de la clase
# a la que pertenece y 0 en las demás).

def calcularAccuracy(labels, preds):
  labels = np.argmax(labels, axis = 1)
  preds = np.argmax(preds, axis = 1)
  
  accuracy = sum(labels == preds)/len(labels)
  
  return accuracy

#########################################################################
## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###
#########################################################################

# Esta función pinta dos gráficas, una con la evolución de la función
# de pérdida en el conjunto de train y en el de validación, y otra
# con la evolución del accuracy en el conjunto de train y en el de
# validación. Es necesario pasarle como parámetro el historial
# del entrenamiento del modelo (lo que devuelven las funciones
# fit() y fit_generator()).

def mostrarEvolucion(hist):
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    plt.plot(loss)
    plt.plot(val_loss)
    plt.legend(['Training loss', 'Validation loss'])
    plt.show()
    
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    plt.plot(acc)
    plt.plot(val_acc)
    plt.legend(['Training accuracy','Validation accuracy'])
    plt.show()

print("Ejercicio 3\n")

# Cargar las imágenes

print("Cargando conjunto de datos...")

x_train, y_train, x_test, y_test = cargarDatos("/content/drive/MyDrive/imagenes")

"""## Usar ResNet50 preentrenada en ImageNet como un extractor de características"""

# Apartado A

print("Apartado 1A")

# Definir un objeto de la clase ImageDataGenerator para train y otro para test
# con sus respectivos argumentos.
datagen_tr = keras.preprocessing.image.ImageDataGenerator(featurewise_center = True, featurewise_std_normalization = True, validation_split=0.1)
datagen_tr.fit(x_train)
datagen_te = keras.preprocessing.image.ImageDataGenerator()


# Definir el modelo ResNet50 (preentrenado en ImageNet y sin la última capa).

print("Generando ResNet...")

resnet = ResNet50(include_top=False, weights='imagenet',pooling='avg')
resnet.trainable=False
#resnet.summary()

# Las características extraídas en el paso anterior van a ser la entrada
# de un pequeño modelo de dos capas Fully Conected, donde la última será la que 
# nos clasifique las clases de Caltech-UCSD (200 clases). De esta forma, es 
# como si hubiéramos fijado todos los parámetros de ResNet50 y estuviésemos
# entrenando únicamente las capas añadidas. Definir dicho modelo.
# A completar: definición del modelo, del optimizador y compilación y
# entrenamiento del modelo.
# En la función fit() puedes usar el argumento validation_split

# Modelo con sólo salida

print("Compilando modelo 1...")

x = resnet.output
last = keras.layers.Dense(200, activation = 'softmax')(x)
modelo1 = keras.Model(inputs = resnet.input, outputs = last)
modelo1.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Modelo con una FC más

print("Compilando modelo 2...")

x = keras.layers.Dense(400, activation = 'relu')(x)
last = keras.layers.Dense(200, activation = 'softmax')(x)
modelo2 = keras.Model(inputs = resnet.input, outputs = last)
modelo2.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Entrenamiento

batch_size = 64
epocas = 12

print("Entrenando modelo 1...")

historial1 = modelo1.fit(datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='training'),
                      steps_per_epoch=len(x_train)*0.9/batch_size,
                      epochs=epocas,
                      validation_data=datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='validation'),
                      validation_steps=len(x_train)*0.1/batch_size)

print("Entrenando modelo 2...")

historial2 = modelo2.fit(datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='training'),
                      steps_per_epoch=len(x_train)*0.9/batch_size,
                      epochs=epocas,
                      validation_data=datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='validation'),
                      validation_steps=len(x_train)*0.1/batch_size)

# Resultados
print("Resultados:")
mostrarEvolucion(historial1)
mostrarEvolucion(historial2)

test_pred = modelo1.predict(datagen_te.flow(x_test,y_test,batch_size=1,shuffle=False))
print("Accuracy para test del modelo 1:", calcularAccuracy(y_test,test_pred))

test_pred = modelo2.predict(datagen_te.flow(x_test,y_test,batch_size=1,shuffle=False))
print("Accuracy para test del modelo 2:", calcularAccuracy(y_test,test_pred))

input("\n--- Pulse cualquier tecla para continuar ---\n")



# Apartado B

print("Apartado 1B")

# Definir el modelo ResNet50 (preentrenado en ImageNet y sin la última capa ni Global Average Pooling).

print("Generando modelo 3...")
resnet = ResNet50(include_top=False, weights='imagenet',pooling=None)
resnet.trainable=False

x = resnet.output
x = keras.layers.BatchNormalization(renorm=True)(x)
x = keras.layers.Dense(200, activation = 'softmax')(x)
x = keras.layers.BatchNormalization(renorm=True)(x)
x = keras.layers.Dropout(0.5)(x)
x = keras.layers.GlobalAveragePooling2D()(x)
last = keras.layers.Dense(200, activation = 'softmax')(x)
model = keras.Model(inputs = resnet.input, outputs = last)

#model.summary()

# Compilación y entrenamiento del modelo.
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

batch_size = 64
epocas = 12

print("Entrenando modelo 3...")

historial = model.fit(datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='training'),
                      steps_per_epoch=len(x_train)*0.9/batch_size,
                      epochs=epocas,
                      validation_data=datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='validation'),
                      validation_steps=len(x_train)*0.1/batch_size)

# Resultados
print("Resultados:")
mostrarEvolucion(historial)

test_pred = model.predict(datagen_te.flow(x_test,y_test,batch_size=1,shuffle=False))
print("Accuracy para test del modelo 3:", calcularAccuracy(y_test,test_pred))

input("\n--- Pulse cualquier tecla para continuar ---\n")

"""## Reentrenar ResNet50 (fine tunning)"""

print("Apartado 2")

# Definir un objeto de la clase ImageDataGenerator para train y otro para test
# con sus respectivos argumentos.

print("Generando conjuntos...")
datagen_tr = keras.preprocessing.image.ImageDataGenerator(featurewise_center = True, featurewise_std_normalization = True, validation_split=0.1)
datagen_tr.fit(x_train)
datagen_te = keras.preprocessing.image.ImageDataGenerator()

# Añadir nuevas capas al final de ResNet50 (recuerda que es una instancia de
# la clase Model).

print("Generando modelo...")

resnet = ResNet50(include_top=False, weights='imagenet',pooling='avg')
x = resnet.output
last = keras.layers.Dense(200, activation = 'softmax')(x)
model = keras.Model(inputs = resnet.input, outputs = last)

# Compilación y entrenamiento del modelo.
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

batch_size = 64
epocas = 8

print("Entrenando modelo...")

historial = model.fit(datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='training'),
                      steps_per_epoch=len(x_train)*0.9/batch_size,
                      epochs=epocas,
                      validation_data=datagen_tr.flow(x_train, y_train, batch_size=batch_size, subset='validation'),
                      validation_steps=len(x_train)*0.1/batch_size)

# Resultados
print("Resultados:")
mostrarEvolucion(historial)

test_pred = model.predict(datagen_te.flow(x_test,y_test,batch_size=1,shuffle=False))
print("Accuracy para test del modelo:", calcularAccuracy(y_test,test_pred))